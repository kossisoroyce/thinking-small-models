{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking XGBoost: Multi-Stage Reasoning for Fraud Detection\n",
    "\n",
    "This notebook demonstrates how to make small models \"think\" by applying LLM-inspired reasoning patterns to XGBoost.\n",
    "\n",
    "## Key Concepts\n",
    "- **Multi-step logic**: Decompose fraud detection into specialized reasoning heads\n",
    "- **Self-correction**: A critic model that triggers re-evaluation when uncertain\n",
    "- **Explainability**: Full reasoning trace for every prediction\n",
    "\n",
    "## Architecture\n",
    "```\n",
    "Input Features\n",
    "     │\n",
    "     ▼\n",
    "┌─────────────────┐\n",
    "│  Stage 1: XGB   │ → Per-dimension risk scores (amount, velocity, location...)\n",
    "│  Reasoning Heads│\n",
    "└─────────────────┘\n",
    "     │\n",
    "     ▼\n",
    "┌─────────────────┐\n",
    "│  Stage 2: Hybrid│ → Blended prediction (weighted avg + XGBoost)\n",
    "│  Aggregator     │\n",
    "└─────────────────┘\n",
    "     │\n",
    "     ▼\n",
    "┌─────────────────┐\n",
    "│  Stage 3: XGB   │ → \"Should I reconsider?\" (error detection)\n",
    "│  Critic         │\n",
    "└─────────────────┘\n",
    "     │\n",
    "     ▼\n",
    "┌─────────────────┐\n",
    "│  Stage 4: XGB   │ → Refined prediction (only if critic flags)\n",
    "│  Refiner        │\n",
    "└─────────────────┘\n",
    "     │\n",
    "     ▼\n",
    "Final Decision + Reasoning Trace\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score\n",
    "import xgboost as xgb\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Local imports\n",
    "from data_generator import get_feature_groups, get_all_features\n",
    "\n",
    "# Constants\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "print(f\"XGBoost version: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('fraud_dataset.csv')\n",
    "FEATURE_GROUPS = get_feature_groups()\n",
    "ALL_FEATURES = get_all_features()\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Fraud rate: {df['is_fraud'].mean():.2%}\")\n",
    "print(f\"\\nFeature groups: {list(FEATURE_GROUPS.keys())}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X = df[ALL_FEATURES]\n",
    "y = df['is_fraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "SCALE_WEIGHT = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "print(f\"Train: {len(X_train):,} samples ({y_train.mean():.2%} fraud)\")\n",
    "print(f\"Test:  {len(X_test):,} samples ({y_test.mean():.2%} fraud)\")\n",
    "print(f\"Scale weight: {SCALE_WEIGHT:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard XGBoost baseline\n",
    "baseline = xgb.XGBClassifier(\n",
    "    n_estimators=100, max_depth=6, learning_rate=0.1,\n",
    "    scale_pos_weight=SCALE_WEIGHT, random_state=RANDOM_STATE, eval_metric='auc'\n",
    ")\n",
    "baseline.fit(X_train, y_train)\n",
    "baseline_preds = baseline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== BASELINE: Standard XGBoost ===\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(y_test, baseline_preds):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, (baseline_preds > 0.5).astype(int), target_names=['Legit', 'Fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Stage 1: Reasoning Heads\n",
    "\n",
    "Train specialized models for each fraud dimension. Each head focuses on one aspect:\n",
    "- **Amount head**: Transaction amount patterns\n",
    "- **Velocity head**: Transaction frequency\n",
    "- **Merchant head**: Merchant risk factors\n",
    "- **Location head**: Geographic signals\n",
    "- **Device head**: Device/channel risk\n",
    "- **Time head**: Temporal patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReasoningHead:\n",
    "    \"\"\"A specialized model for one fraud dimension.\"\"\"\n",
    "    name: str\n",
    "    features: List[str]\n",
    "    model: Optional[xgb.XGBClassifier] = None\n",
    "    weight: float = 1.0\n",
    "    \n",
    "    def train(self, X: pd.DataFrame, y: pd.Series, scale_weight: float):\n",
    "        self.model = xgb.XGBClassifier(\n",
    "            n_estimators=60, max_depth=5, learning_rate=0.1,\n",
    "            scale_pos_weight=scale_weight, random_state=RANDOM_STATE, eval_metric='auc'\n",
    "        )\n",
    "        self.model.fit(X[self.features], y)\n",
    "        # Learn weight from training performance\n",
    "        self.weight = roc_auc_score(y, self.predict_proba(X))\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        return self.model.predict_proba(X[self.features])[:, 1]\n",
    "    \n",
    "    def get_reasoning(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        p = self.predict_proba(X)\n",
    "        return pd.DataFrame({\n",
    "            f'head_{self.name}_score': p,\n",
    "            f'head_{self.name}_signal': (p > 0.5).astype(int)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train reasoning heads\n",
    "reasoning_heads = {}\n",
    "print(\"Training Stage 1: Reasoning Heads\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, features in FEATURE_GROUPS.items():\n",
    "    head = ReasoningHead(name, features)\n",
    "    head.train(X_train, y_train, SCALE_WEIGHT)\n",
    "    reasoning_heads[name] = head\n",
    "    \n",
    "    test_auc = roc_auc_score(y_test, head.predict_proba(X_test))\n",
    "    print(f\"  {name:12s}: AUC={test_auc:.4f}, weight={head.weight:.3f}\")\n",
    "\n",
    "# Normalize weights\n",
    "total_weight = sum(h.weight for h in reasoning_heads.values())\n",
    "for h in reasoning_heads.values():\n",
    "    h.weight /= total_weight\n",
    "\n",
    "print(\"\\nNormalized weights:\")\n",
    "for name, head in reasoning_heads.items():\n",
    "    print(f\"  {name:12s}: {head.weight:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get all head outputs\n",
    "def get_stage1_outputs(X: pd.DataFrame, heads: Dict[str, ReasoningHead]) -> pd.DataFrame:\n",
    "    return pd.concat([h.get_reasoning(X) for h in heads.values()], axis=1)\n",
    "\n",
    "# Generate stage 1 outputs\n",
    "stage1_train = get_stage1_outputs(X_train, reasoning_heads)\n",
    "stage1_test = get_stage1_outputs(X_test, reasoning_heads)\n",
    "\n",
    "print(f\"Stage 1 output columns: {list(stage1_train.columns)}\")\n",
    "stage1_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Stage 2: Hybrid Aggregator\n",
    "\n",
    "Combines head outputs using a **hybrid approach**:\n",
    "- 60% weighted average (interpretable, faithful)\n",
    "- 40% XGBoost with interactions (powerful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLEND_RATIO = 0.6  # 60% weighted avg, 40% XGBoost\n",
    "\n",
    "def weighted_average(s1: pd.DataFrame, heads: Dict[str, ReasoningHead]) -> np.ndarray:\n",
    "    \"\"\"Direct weighted average of head scores.\"\"\"\n",
    "    result = np.zeros(len(s1))\n",
    "    for name, head in heads.items():\n",
    "        result += head.weight * s1[f'head_{name}_score'].values\n",
    "    return result\n",
    "\n",
    "def build_aggregator_features(s1: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Build XGBoost aggregator input with pairwise interactions.\"\"\"\n",
    "    X_agg = s1.copy()\n",
    "    score_cols = [c for c in s1.columns if '_score' in c]\n",
    "    for i, h1 in enumerate(score_cols):\n",
    "        for h2 in score_cols[i+1:]:\n",
    "            X_agg[f'{h1}_{h2}_int'] = s1[h1] * s1[h2]\n",
    "    return X_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute weighted average predictions\n",
    "wav_train = weighted_average(stage1_train, reasoning_heads)\n",
    "wav_test = weighted_average(stage1_test, reasoning_heads)\n",
    "\n",
    "# Build features for XGBoost aggregator\n",
    "X_agg_train = build_aggregator_features(stage1_train)\n",
    "X_agg_test = build_aggregator_features(stage1_test)\n",
    "\n",
    "# Train XGBoost aggregator\n",
    "xgb_aggregator = xgb.XGBClassifier(\n",
    "    n_estimators=30, max_depth=4, learning_rate=0.1,\n",
    "    scale_pos_weight=SCALE_WEIGHT, random_state=RANDOM_STATE, eval_metric='auc'\n",
    ")\n",
    "xgb_aggregator.fit(X_agg_train, y_train.reset_index(drop=True))\n",
    "\n",
    "xgb_train = xgb_aggregator.predict_proba(X_agg_train)[:, 1]\n",
    "xgb_test = xgb_aggregator.predict_proba(X_agg_test)[:, 1]\n",
    "\n",
    "# Blend predictions\n",
    "agg_train = BLEND_RATIO * wav_train + (1 - BLEND_RATIO) * xgb_train\n",
    "agg_test = BLEND_RATIO * wav_test + (1 - BLEND_RATIO) * xgb_test\n",
    "\n",
    "print(\"=== Stage 2: Hybrid Aggregator ===\")\n",
    "print(f\"Weighted Avg AUC:    {roc_auc_score(y_test, wav_test):.4f}\")\n",
    "print(f\"XGBoost AUC:         {roc_auc_score(y_test, xgb_test):.4f}\")\n",
    "print(f\"Blended AUC:         {roc_auc_score(y_test, agg_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Stage 3: Critic (Self-Correction Gate)\n",
    "\n",
    "The critic learns to predict **when the aggregator will be wrong**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cross-validation errors (more realistic than train errors)\n",
    "cv_xgb = cross_val_predict(\n",
    "    xgb.XGBClassifier(n_estimators=30, max_depth=4, scale_pos_weight=SCALE_WEIGHT, \n",
    "                      random_state=RANDOM_STATE, eval_metric='auc'),\n",
    "    X_agg_train, y_train.reset_index(drop=True), cv=5, method='predict_proba'\n",
    ")[:, 1]\n",
    "\n",
    "cv_blend = BLEND_RATIO * wav_train + (1 - BLEND_RATIO) * cv_xgb\n",
    "aggregator_errors = ((cv_blend > 0.5).astype(int) != y_train.reset_index(drop=True).values).astype(int)\n",
    "\n",
    "print(f\"Aggregator CV errors: {aggregator_errors.sum()} ({aggregator_errors.mean():.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_critic_features(s1: pd.DataFrame, wav: np.ndarray, \n",
    "                          xgb_pred: np.ndarray, blend: np.ndarray,\n",
    "                          heads: Dict[str, ReasoningHead]) -> pd.DataFrame:\n",
    "    \"\"\"Build critic input features.\"\"\"\n",
    "    d = pd.DataFrame()\n",
    "    d['blend_pred'] = blend\n",
    "    d['wav_pred'] = wav\n",
    "    d['xgb_pred'] = xgb_pred\n",
    "    d['wav_xgb_diff'] = np.abs(wav - xgb_pred)  # Disagreement between methods\n",
    "    d['blend_conf'] = np.abs(blend - 0.5) * 2\n",
    "    \n",
    "    for name in heads.keys():\n",
    "        score = s1[f'head_{name}_score'].values\n",
    "        d[f'{name}_score'] = score\n",
    "        d[f'{name}_vs_blend'] = np.abs(score - blend)\n",
    "    \n",
    "    score_cols = [c for c in s1.columns if '_score' in c]\n",
    "    d['head_std'] = s1[score_cols].std(axis=1).values\n",
    "    d['head_range'] = s1[score_cols].max(axis=1).values - s1[score_cols].min(axis=1).values\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build critic features\n",
    "critic_train_feats = build_critic_features(stage1_train, wav_train, xgb_train, agg_train, reasoning_heads)\n",
    "critic_test_feats = build_critic_features(stage1_test, wav_test, xgb_test, agg_test, reasoning_heads)\n",
    "\n",
    "# Train critic\n",
    "critic = xgb.XGBClassifier(\n",
    "    n_estimators=100, max_depth=5, learning_rate=0.05,\n",
    "    random_state=RANDOM_STATE, eval_metric='auc'\n",
    ")\n",
    "critic.fit(critic_train_feats, aggregator_errors)\n",
    "\n",
    "# Find optimal threshold\n",
    "critic_train_scores = critic.predict_proba(critic_train_feats)[:, 1]\n",
    "best_threshold, best_f1 = 0.3, 0\n",
    "for t in np.arange(0.1, 0.7, 0.02):\n",
    "    flags = (critic_train_scores > t).astype(int)\n",
    "    if flags.sum() > 0:\n",
    "        f1 = f1_score(aggregator_errors, flags, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_threshold = f1, t\n",
    "\n",
    "CRITIC_THRESHOLD = best_threshold\n",
    "critic_test_scores = critic.predict_proba(critic_test_feats)[:, 1]\n",
    "\n",
    "print(\"=== Stage 3: Critic ===\")\n",
    "print(f\"Critic F1 (error detection): {best_f1:.4f}\")\n",
    "print(f\"Optimal threshold: {CRITIC_THRESHOLD:.2f}\")\n",
    "print(f\"Test samples flagged: {(critic_test_scores > CRITIC_THRESHOLD).sum()} / {len(critic_test_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Stage 4: Refiner\n",
    "\n",
    "A stronger model that re-evaluates cases flagged by the critic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine original features with stage 1 outputs for refiner\n",
    "X_ref_train = pd.concat([X_train.reset_index(drop=True), stage1_train], axis=1)\n",
    "X_ref_test = pd.concat([X_test.reset_index(drop=True), stage1_test], axis=1)\n",
    "\n",
    "# Train refiner with emphasis on hard cases\n",
    "refiner = xgb.XGBClassifier(\n",
    "    n_estimators=180, max_depth=8, learning_rate=0.03,\n",
    "    scale_pos_weight=SCALE_WEIGHT, random_state=RANDOM_STATE, eval_metric='auc'\n",
    ")\n",
    "\n",
    "# Weight errors more heavily\n",
    "sample_weights = np.where(aggregator_errors == 1, 8.0, 1.0)\n",
    "refiner.fit(X_ref_train, y_train.reset_index(drop=True), sample_weight=sample_weights)\n",
    "\n",
    "refiner_test = refiner.predict_proba(X_ref_test)[:, 1]\n",
    "\n",
    "print(\"=== Stage 4: Refiner ===\")\n",
    "print(f\"Refiner AUC: {roc_auc_score(y_test, refiner_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Complete Thinking Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ThinkingXGBoostPipeline:\n",
    "    \"\"\"Complete 4-stage thinking pipeline with hybrid aggregation.\"\"\"\n",
    "    reasoning_heads: Dict[str, ReasoningHead]\n",
    "    xgb_aggregator: xgb.XGBClassifier\n",
    "    critic: xgb.XGBClassifier\n",
    "    refiner: xgb.XGBClassifier\n",
    "    critic_threshold: float = 0.43\n",
    "    blend_ratio: float = 0.6\n",
    "    \n",
    "    def predict_with_reasoning(self, X: pd.DataFrame) -> Tuple[np.ndarray, pd.DataFrame]:\n",
    "        \"\"\"Run full pipeline with reasoning trace.\"\"\"\n",
    "        # Stage 1: Reasoning heads\n",
    "        s1 = get_stage1_outputs(X, self.reasoning_heads)\n",
    "        \n",
    "        # Stage 2: Hybrid aggregation\n",
    "        wav = weighted_average(s1, self.reasoning_heads)\n",
    "        X_agg = build_aggregator_features(s1)\n",
    "        xgb_pred = self.xgb_aggregator.predict_proba(X_agg)[:, 1]\n",
    "        agg_preds = self.blend_ratio * wav + (1 - self.blend_ratio) * xgb_pred\n",
    "        \n",
    "        # Stage 3: Critic\n",
    "        critic_feats = build_critic_features(s1, wav, xgb_pred, agg_preds, self.reasoning_heads)\n",
    "        critic_scores = self.critic.predict_proba(critic_feats)[:, 1]\n",
    "        needs_refinement = critic_scores > self.critic_threshold\n",
    "        \n",
    "        # Stage 4: Selective refinement\n",
    "        final_preds = agg_preds.copy()\n",
    "        if needs_refinement.any():\n",
    "            X_ref = pd.concat([X.reset_index(drop=True), s1], axis=1)\n",
    "            ref_preds = self.refiner.predict_proba(X_ref)[:, 1]\n",
    "            final_preds[needs_refinement] = ref_preds[needs_refinement]\n",
    "        \n",
    "        # Build reasoning trace\n",
    "        trace = s1.copy()\n",
    "        trace['weighted_avg'] = wav\n",
    "        trace['xgb_pred'] = xgb_pred\n",
    "        trace['aggregator_pred'] = agg_preds\n",
    "        trace['critic_score'] = critic_scores\n",
    "        trace['needs_refinement'] = needs_refinement.astype(int)\n",
    "        trace['final_pred'] = final_preds\n",
    "        trace['decision'] = (final_preds > 0.5).astype(int)\n",
    "        \n",
    "        return final_preds, trace\n",
    "    \n",
    "    def explain(self, X_single: pd.DataFrame, idx: int = 0) -> str:\n",
    "        \"\"\"Generate human-readable explanation.\"\"\"\n",
    "        _, trace = self.predict_with_reasoning(X_single)\n",
    "        row = trace.iloc[idx]\n",
    "        \n",
    "        lines = [\"<REASONING>\"]\n",
    "        for name in self.reasoning_heads.keys():\n",
    "            score = row[f'head_{name}_score']\n",
    "            lines.append(f\"  {name:12s} risk: {score:.3f}\")\n",
    "        lines.append(\"  \" + \"-\"*20)\n",
    "        lines.append(f\"  Weighted avg:     {row['weighted_avg']:.3f}\")\n",
    "        lines.append(f\"  XGBoost pred:     {row['xgb_pred']:.3f}\")\n",
    "        lines.append(f\"  Blended:          {row['aggregator_pred']:.3f}\")\n",
    "        lines.append(f\"  Critic score:     {row['critic_score']:.3f}\")\n",
    "        if row['needs_refinement']:\n",
    "            lines.append(\"  [!] REFINEMENT TRIGGERED\")\n",
    "        lines.append(\"</REASONING>\")\n",
    "        lines.append(\"\")\n",
    "        lines.append(\"<SOLUTION>\")\n",
    "        decision = \"FRAUD\" if row['decision'] == 1 else \"LEGITIMATE\"\n",
    "        lines.append(f\"  Probability: {row['final_pred']:.3f}\")\n",
    "        lines.append(f\"  Decision:    {decision}\")\n",
    "        lines.append(\"</SOLUTION>\")\n",
    "        \n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "pipeline = ThinkingXGBoostPipeline(\n",
    "    reasoning_heads=reasoning_heads,\n",
    "    xgb_aggregator=xgb_aggregator,\n",
    "    critic=critic,\n",
    "    refiner=refiner,\n",
    "    critic_threshold=CRITIC_THRESHOLD,\n",
    "    blend_ratio=BLEND_RATIO\n",
    ")\n",
    "\n",
    "# Run on test set\n",
    "final_preds, reasoning_trace = pipeline.predict_with_reasoning(X_test)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"THINKING XGBOOST PIPELINE - RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nROC-AUC: {roc_auc_score(y_test, final_preds):.4f}\")\n",
    "print(f\"Samples refined: {reasoning_trace['needs_refinement'].sum()} / {len(reasoning_trace)}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, (final_preds > 0.5).astype(int), target_names=['Legit', 'Fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Comparison: Baseline vs Thinking Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nBaseline XGBoost ROC-AUC:  {roc_auc_score(y_test, baseline_preds):.4f}\")\n",
    "print(f\"Thinking Pipeline ROC-AUC: {roc_auc_score(y_test, final_preds):.4f}\")\n",
    "\n",
    "delta = roc_auc_score(y_test, final_preds) - roc_auc_score(y_test, baseline_preds)\n",
    "print(f\"\\nDifference: {delta:+.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"KEY ADVANTAGE: Explainable reasoning trace!\")\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Explainable Reasoning Traces\n",
    "\n",
    "The key differentiator: we can show **why** the model made each decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example Reasoning Traces ===\")\n",
    "\n",
    "# Show fraud and legitimate examples\n",
    "fraud_idx = y_test[y_test == 1].index[0]\n",
    "legit_idx = y_test[y_test == 0].index[0]\n",
    "\n",
    "print(\"\\n--- FRAUD CASE (Actual: FRAUD) ---\")\n",
    "print(pipeline.explain(X_test.loc[[fraud_idx]]))\n",
    "\n",
    "print(\"\\n--- LEGITIMATE CASE (Actual: LEGIT) ---\")\n",
    "print(pipeline.explain(X_test.loc[[legit_idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a case where refinement was triggered\n",
    "refined_indices = reasoning_trace[reasoning_trace['needs_refinement'] == 1].index\n",
    "\n",
    "if len(refined_indices) > 0:\n",
    "    print(\"\\n--- REFINED CASE (Self-Correction Triggered) ---\")\n",
    "    idx = refined_indices[0]\n",
    "    actual = \"FRAUD\" if y_test.iloc[idx] == 1 else \"LEGIT\"\n",
    "    print(f\"Actual: {actual}\")\n",
    "    print(pipeline.explain(X_test.iloc[[idx]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Reasoning Quality Score (RQS) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rqs_evaluator import RQSEvaluator\n",
    "\n",
    "evaluator = RQSEvaluator()\n",
    "rqs_result = evaluator.evaluate(pipeline, X_test, y_test, n_perturbations=100)\n",
    "\n",
    "print(rqs_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target comparison\n",
    "print(\"Target Analysis:\")\n",
    "print(\"-\" * 50)\n",
    "targets = {\n",
    "    'Decomposability': (rqs_result.Decomposability, 0.70, '>'),\n",
    "    'Self-Correction': (rqs_result.Self_Correction_F1, 0.30, '>'),\n",
    "    'Coherence': (rqs_result.Reasoning_Coherence, 0.50, '>'),\n",
    "    'Faithfulness': (rqs_result.Explanation_Faithfulness, 0.60, '>'),\n",
    "    'Graceful Degradation': (rqs_result.Graceful_Degradation, 0.50, '<'),\n",
    "}\n",
    "\n",
    "for name, (value, target, direction) in targets.items():\n",
    "    if direction == '>':\n",
    "        met = value > target\n",
    "        symbol = '>' \n",
    "    else:\n",
    "        met = value < target\n",
    "        symbol = '<'\n",
    "    status = \"✓\" if met else \"✗\"\n",
    "    print(f\"  {name:20s}: {value:.3f} ({symbol}{target}) {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Summary\n",
    "\n",
    "We built a **Thinking XGBoost** pipeline that:\n",
    "\n",
    "1. **Decomposes** fraud detection into specialized reasoning heads\n",
    "2. **Aggregates** using a hybrid weighted average + XGBoost approach\n",
    "3. **Self-corrects** by detecting uncertain predictions with a critic model\n",
    "4. **Refines** flagged cases with a stronger model\n",
    "5. **Explains** every prediction with a full reasoning trace\n",
    "\n",
    "### Key Contributions\n",
    "- Novel application of LLM \"thinking\" patterns to gradient boosting\n",
    "- Formal **Reasoning Quality Score (RQS)** framework for evaluating small model reasoning\n",
    "- Practical self-correction mechanism that improves interpretability without sacrificing accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
